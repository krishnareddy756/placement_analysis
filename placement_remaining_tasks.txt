Campus Placement Prediction — Where You Are & What’s Left (Quick Guide)

YOU ARE HERE
- Data: placementdata.csv (10,000 rows, 12 columns).
- Prep done: categorical encoding (ExtracurricularActivities, PlacementTraining, PlacementStatus); EDA; train/test split.
- Models tried: Logistic Regression, Random Forest, XGBoost.
- Current scores (test set):
  • Logistic Regression — Accuracy: 0.7945, ROC-AUC: 0.8768 (best & most interpretable)
  • Random Forest — Accuracy: 0.781, ROC-AUC: 0.8678
  • XGBoost — Accuracy: 0.7825, ROC-AUC: 0.8700

REMAINING TASKS (DO THESE IN ORDER)

DAY 3 — Insights & Storytelling
1) Lock model & seed
   - Fix the random_state (e.g., 42) for train/test split and models.
   - Save the chosen model (Logistic Regression) with joblib along with the list of feature columns used.
2) Feature importance (for the chosen model)
   - Coefficients (after standardizing features): rank by absolute value.
   - Permutation importance on the test split: use sklearn.inspection.permutation_importance.
   - (Optional) SHAP for LR or XGB for extra interpretability.
3) Clean, report-ready plots
   - Bar chart: top 8 features (coef-abs & permutation side-by-side or two separate bars).
   - Smooth ROC curve and confusion matrix for the final model.
4) One-paragraph “insights” summary
   - In plain language, explain which variables move the probability up/down and what that means.
5) Resume-ready project description
   - 5–7 lines with Objective, Data, Approach, Best model & metrics, Key insights, and a line on deployment.

DAY 4–7 — Optional Streamlit Dashboard
1) Prepare assets
   - Save trained model: models/lr_model.pkl
   - Save metadata: models/feature_columns.json
2) Streamlit app (app.py)
   - Tabs: Overview, EDA, Predict.
   - Predict form: inputs for all features (except StudentID), outputs probability + class.
3) Local run & deploy
   - requirements.txt (streamlit, pandas, scikit-learn, shap, matplotlib, xgboost==<your-version> if needed)
   - streamlit run app.py (local)
   - Deploy to Streamlit Cloud: add files to a GitHub repo, connect, set Python version and requirements.

REFERENCE CODE SNIPPETS (DROP INTO YOUR COLAB)

# 1) Save the final Logistic Regression model
import json, joblib
feature_cols = ['CGPA','Internships','Projects','Workshops/Certifications','AptitudeTestScore',
                'SoftSkillsRating','ExtracurricularActivities','PlacementTraining','SSC_Marks','HSC_Marks']
joblib.dump(best_lr, 'models/lr_model.pkl')
with open('models/feature_columns.json','w') as f:
    json.dump(feature_cols, f)

# 2) Coefficient importance (assuming StandardScaler used)
import numpy as np
import pandas as pd
coefs = pd.DataFrame({
    'feature': feature_cols,
    'coef': best_lr.named_steps['logreg'].coef_.ravel()
}).assign(coef_abs=lambda d: d['coef'].abs()).sort_values('coef_abs', ascending=False)

# 3) Permutation importance (on test set X_test, y_test)
from sklearn.inspection import permutation_importance
r = permutation_importance(best_lr, X_test, y_test, n_repeats=20, random_state=42, scoring='roc_auc')
perm = pd.DataFrame({'feature': feature_cols, 'perm_importance': r.importances_mean}).sort_values('perm_importance', ascending=False)

# 4) ROC curve & Confusion matrix
from sklearn.metrics import RocCurveDisplay, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

RocCurveDisplay.from_estimator(best_lr, X_test, y_test)
plt.title('ROC — Logistic Regression')
plt.show()

ConfusionMatrixDisplay.from_estimator(best_lr, X_test, y_test)
plt.title('Confusion Matrix — Logistic Regression')
plt.show()

# 5) Streamlit app skeleton (app.py)